{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "import lightgbm as lgb\n",
    "import gc \n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from pandas \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows',600)\n",
    "pd.set_option('display.max_columns',50)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Code/Data Science Code Base/Kaggle Data/Predict_Future_Sales/'\n",
    "sales = pd.read_csv(data_path+'sales_train_v2.csv')\n",
    "shops = pd.read_csv(data_path+'shops.csv')\n",
    "items = pd.read_csv(data_path+'items.csv')\n",
    "item_cats = pd.read_csv(data_path+'item_categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating item/shop month aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['shop_id','item_id','date_block_num']\n",
    "\n",
    "grid=[]\n",
    "\n",
    "for block_num in sales.date_block_num.unique():\n",
    "    curr_shops = sales.loc[sales['date_block_num']==block_num,'shop_id'].unique()\n",
    "    curr_items = sales.loc[sales['date_block_num']==block_num,'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[curr_shops,curr_items,[block_num]])),dtype='int32'))\n",
    "\n",
    "grid = pd.DataFrame(np.vstack(grid),columns = index_cols,dtype=np.int32)\n",
    "\n",
    "# Grouping data to get all item/shop-month agrregates \n",
    "\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "\n",
    "\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "\n",
    "# Now groupby data to get all shop_month agregate\n",
    "\n",
    "gb = sales.groupby(['shop_id','date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "\n",
    "all_data = pd.merge(all_data,gb,how='left',on=['shop_id','date_block_num']).fillna(0)\n",
    "\n",
    "# Now groupby data to get item_month aggregates \n",
    "gb = sales.groupby(['item_id','date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "\n",
    "all_data = pd.merge(all_data,gb,how='left',on=['item_id','date_block_num']).fillna(0)\n",
    "\n",
    "#Downcasting to save memory 64 to 32 bit \n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid,gb\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Lag Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_rename = list(all_data.columns.difference(index_cols))\n",
    "\n",
    "shift_range = [1,2,3,4,5,12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "    train_shift = all_data[index_cols+col_to_rename].copy()\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num']+month_shift\n",
    "    foo = lambda x: '{}_lag_{}'.format(x,month_shift) if x in col_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo) \n",
    "    all_data = pd.merge(all_data,train_shift,how='left',on=index_cols).fillna(0)\n",
    "\n",
    "del train_shift\n",
    "\n",
    "# Not using old data from 2013 \n",
    "all_data = all_data[all_data['date_block_num']>=12]\n",
    "\n",
    "fit_cols  = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]]\n",
    "to_drop_cols = list(set(list(all_data.columns))-(set(fit_cols)|set(index_cols))) + ['date_block_num']\n",
    "\n",
    "# Map Category to items \n",
    "\n",
    "item_cat = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data  = pd.merge(all_data,item_cat,how='left',on='item_id')\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore\n",
    "store = HDFStore('all_data.h5')\n",
    "store.put('all_data',all_data,format='table',data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = HDFStore('all_data.h5')\n",
    "all_data = store['all_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = all_data['date_block_num']\n",
    "last_block = dates.max()\n",
    "\n",
    "dates_train = dates[dates<last_block]\n",
    "dates_test = dates[dates==last_block]\n",
    "\n",
    "X_train = all_data.loc[dates<last_block].drop(to_drop_cols,axis=1)\n",
    "X_test = all_data.loc[dates==last_block].drop(to_drop_cols,axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates<last_block,'target'].values\n",
    "y_test = all_data.loc[dates==last_block,'target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling a part of the data cause potato laptop :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data['date_block_num']>=25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2178627, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.243272\n",
      "Train R-squared for LightGBM is 0.679944\n",
      "increased num leaves and learning rate,decreased min_data_in_leaf\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                'feature_fraction':0.75,\n",
    "                'metric':'rmse',\n",
    "                'min_data_in_leaf':100,\n",
    "                'bagging_fraction':0.75,\n",
    "                'learning_rate':0.25,\n",
    "                'objective':'mse',\n",
    "                'bagging_seed':2**7,\n",
    "                'num_leaves':2**9,\n",
    "                'max_depth':20,\n",
    "                'bagging_freq':1,\n",
    "                'verbose':0\n",
    "            }\n",
    "\n",
    "\n",
    "model = lgb.train(lgb_params,lgb.Dataset(X_train,label=y_train),num_boost_round=200)\n",
    "pred_lgb_val = model.predict(X_test)\n",
    "pred_lgb_tr = model.predict(X_train)\n",
    "\n",
    "\n",
    "print('Test R-squared for LightGBM is %f'% r2_score(y_test,pred_lgb_val))\n",
    "print('Train R-squared for LightGBM is %f'%r2_score(y_train,pred_lgb_tr))\n",
    "print(\"increased num leaves and learning rate,decreased min_data_in_leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "import lightgbm as lgb\n",
    "import gc \n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from pandas import HDFStore\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pandas import HDFStore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def plot_features(booster, figsize):    \n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows',600)\n",
    "pd.set_option('display.max_columns',50)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from itertools import product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all datasets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Code/Data Science Code Base/Kaggle Data/Predict_Future_Sales/'\n",
    "sales = pd.read_csv(data_path+'sales_train_v2.csv')\n",
    "shops = pd.read_csv(data_path+'shops-translated.csv')\n",
    "items = pd.read_csv(data_path+'items.csv')\n",
    "item_cats = pd.read_csv(data_path+'item_categories-translated.csv')\n",
    "test = pd.read_csv(data_path+'test.csv')\n",
    "calendar = pd.read_csv(data_path+'calendar.csv')\n",
    "usd_rub = pd.read_csv(data_path+'usd-rub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop_duplicates(inplace=True)\n",
    "shops.drop_duplicates(inplace=True)\n",
    "items.drop_duplicates(inplace=True)\n",
    "item_cats.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales.item_cnt_day<1000]\n",
    "sales = sales[sales.item_price<100000]\n",
    "sales = sales[sales.item_price>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the encoded_train_test.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_test = HDFStore('encoded_train_test.h5')\n",
    "all_data1 = encoded_train_test['encoded_train_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2 = all_data1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function for lag features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features_func(lag_features,time_range,df,non_lag_features):\n",
    "    for month_shift in tqdm_notebook(time_range):\n",
    "        shift_df = df[non_lag_features+lag_features].copy()\n",
    "        shift_df['date_block_num'] = shift_df['date_block_num'] + month_shift\n",
    "        foo = lambda x: '{}_lag_{}'.format(x,month_shift) if x in lag_features else x\n",
    "        shift_df = shift_df.rename(columns=foo)\n",
    "        df = pd.merge(df,shift_df,how='left',on=non_lag_features).fillna(0)\n",
    "    del shift_df\n",
    "    gc.collect();\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating lag features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = [col for col in all_data1.columns if (('target' in col.split('_'))|('encoded' in col.split('_')))]\n",
    "non_lag_features = list(all_data1.columns.difference(lag_features))\n",
    "time_range = [1,2,3,6,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aab075cc194d6597e1a7b4ae38f65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_data2 = lag_features_func(lag_features,time_range,all_data2,non_lag_features)\n",
    "all_data2 = all_data2[all_data2.date_block_num>=12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding supplementary information\n",
    "* Add Month (done)\n",
    "* Add number of holidays (national holidays)(done)\n",
    "* Add season (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['month'] = calendar.date.apply(lambda x: int(x.split('-')[1]))\n",
    "gp = calendar.groupby('month').agg({'holiday':{'holidays_in_month':'sum'}})\n",
    "gp.columns = [col[0] if col[-1]=='' else col[-1] for col in gp.columns.values]\n",
    "all_data2['month'] = all_data2.date_block_num.apply(lambda block: (block%12) +1)\n",
    "all_data2 = pd.merge(all_data2,gp,how='left',on=['month'])\n",
    "del gp\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = HDFStore('encoded_train_test_lag.h5')\n",
    "store.put('encoded_train_test_lag',all_data2,format='table',data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling \n",
    "* Using Lightgbm to train models \n",
    "* validation set is the last month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff to do \n",
    "* Use mean_encodings of train and map to validation (done)\n",
    "* Prepare test set(done) \n",
    "* tune model \n",
    "* Clip predictions and figure out when and how to do it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = all_data2['date_block_num']\n",
    "test_block = dates.max()\n",
    "val_block = test_block -1\n",
    "dates_train = dates[dates<val_block]\n",
    "dates_val = dates[dates==val_block]\n",
    "present_encoded = [col for col in all_data2.columns if col.split('_')[-1]=='encoded']\n",
    "\n",
    "X_train = all_data2.loc[dates<val_block].drop(['target','target_shop','target_item']+present_encoded,axis=1)\n",
    "X_val = all_data2.loc[dates== val_block].drop(['target','target_shop','target_item']+present_encoded,axis=1)\n",
    "X_test = all_data2.loc[dates==test_block].drop(['target','target_shop','target_item']+present_encoded,axis=1)\n",
    "\n",
    "y_train = all_data2.loc[dates<val_block,'target'].values\n",
    "y_val = all_data2.loc[dates==val_block,'target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:43:45] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\tvalidation_0-rmse:3.38582\tvalidation_1-rmse:2.59711\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-rmse:3.30173\tvalidation_1-rmse:2.51783\n",
      "[2]\tvalidation_0-rmse:3.21919\tvalidation_1-rmse:2.44098\n",
      "[3]\tvalidation_0-rmse:3.14943\tvalidation_1-rmse:2.38248\n",
      "[4]\tvalidation_0-rmse:3.08873\tvalidation_1-rmse:2.32854\n",
      "[5]\tvalidation_0-rmse:3.0324\tvalidation_1-rmse:2.27514\n",
      "[6]\tvalidation_0-rmse:2.99192\tvalidation_1-rmse:2.23911\n",
      "[7]\tvalidation_0-rmse:2.94907\tvalidation_1-rmse:2.20544\n",
      "[8]\tvalidation_0-rmse:2.91293\tvalidation_1-rmse:2.17792\n",
      "[9]\tvalidation_0-rmse:2.88197\tvalidation_1-rmse:2.1528\n",
      "[10]\tvalidation_0-rmse:2.85533\tvalidation_1-rmse:2.13528\n",
      "[11]\tvalidation_0-rmse:2.83353\tvalidation_1-rmse:2.12034\n",
      "[12]\tvalidation_0-rmse:2.81472\tvalidation_1-rmse:2.11189\n",
      "[13]\tvalidation_0-rmse:2.79896\tvalidation_1-rmse:2.10459\n",
      "[14]\tvalidation_0-rmse:2.78192\tvalidation_1-rmse:2.09643\n",
      "[15]\tvalidation_0-rmse:2.77064\tvalidation_1-rmse:2.09609\n",
      "[16]\tvalidation_0-rmse:2.75587\tvalidation_1-rmse:2.09387\n",
      "[17]\tvalidation_0-rmse:2.74527\tvalidation_1-rmse:2.09914\n",
      "[18]\tvalidation_0-rmse:2.73217\tvalidation_1-rmse:2.09717\n",
      "[19]\tvalidation_0-rmse:2.71921\tvalidation_1-rmse:2.08438\n",
      "[20]\tvalidation_0-rmse:2.71203\tvalidation_1-rmse:2.08805\n",
      "[21]\tvalidation_0-rmse:2.70423\tvalidation_1-rmse:2.09239\n",
      "[22]\tvalidation_0-rmse:2.69412\tvalidation_1-rmse:2.08588\n",
      "[23]\tvalidation_0-rmse:2.68599\tvalidation_1-rmse:2.08638\n",
      "[24]\tvalidation_0-rmse:2.67992\tvalidation_1-rmse:2.08702\n",
      "[25]\tvalidation_0-rmse:2.67569\tvalidation_1-rmse:2.08819\n",
      "[26]\tvalidation_0-rmse:2.66667\tvalidation_1-rmse:2.08218\n",
      "[27]\tvalidation_0-rmse:2.66098\tvalidation_1-rmse:2.07928\n",
      "[28]\tvalidation_0-rmse:2.65558\tvalidation_1-rmse:2.07948\n",
      "[29]\tvalidation_0-rmse:2.65105\tvalidation_1-rmse:2.07788\n",
      "[30]\tvalidation_0-rmse:2.64627\tvalidation_1-rmse:2.08253\n",
      "[31]\tvalidation_0-rmse:2.64232\tvalidation_1-rmse:2.07937\n",
      "[32]\tvalidation_0-rmse:2.63697\tvalidation_1-rmse:2.08752\n",
      "[33]\tvalidation_0-rmse:2.63114\tvalidation_1-rmse:2.07891\n",
      "[34]\tvalidation_0-rmse:2.62663\tvalidation_1-rmse:2.08207\n",
      "[35]\tvalidation_0-rmse:2.62335\tvalidation_1-rmse:2.0818\n",
      "[36]\tvalidation_0-rmse:2.61726\tvalidation_1-rmse:2.07706\n",
      "[37]\tvalidation_0-rmse:2.61203\tvalidation_1-rmse:2.07253\n",
      "[38]\tvalidation_0-rmse:2.60919\tvalidation_1-rmse:2.07175\n",
      "[39]\tvalidation_0-rmse:2.60555\tvalidation_1-rmse:2.06971\n",
      "[40]\tvalidation_0-rmse:2.60165\tvalidation_1-rmse:2.06921\n",
      "[41]\tvalidation_0-rmse:2.5981\tvalidation_1-rmse:2.07313\n",
      "[42]\tvalidation_0-rmse:2.5939\tvalidation_1-rmse:2.06815\n",
      "[43]\tvalidation_0-rmse:2.59089\tvalidation_1-rmse:2.0688\n",
      "[44]\tvalidation_0-rmse:2.58839\tvalidation_1-rmse:2.06609\n",
      "[45]\tvalidation_0-rmse:2.585\tvalidation_1-rmse:2.07037\n",
      "[46]\tvalidation_0-rmse:2.58136\tvalidation_1-rmse:2.06367\n",
      "[47]\tvalidation_0-rmse:2.57907\tvalidation_1-rmse:2.06214\n",
      "[48]\tvalidation_0-rmse:2.57294\tvalidation_1-rmse:2.05647\n",
      "[49]\tvalidation_0-rmse:2.57081\tvalidation_1-rmse:2.05545\n",
      "[50]\tvalidation_0-rmse:2.56794\tvalidation_1-rmse:2.0586\n",
      "[51]\tvalidation_0-rmse:2.56518\tvalidation_1-rmse:2.05666\n",
      "[52]\tvalidation_0-rmse:2.56154\tvalidation_1-rmse:2.05441\n",
      "[53]\tvalidation_0-rmse:2.5596\tvalidation_1-rmse:2.05468\n",
      "[54]\tvalidation_0-rmse:2.55741\tvalidation_1-rmse:2.0546\n",
      "[55]\tvalidation_0-rmse:2.55528\tvalidation_1-rmse:2.05354\n",
      "[56]\tvalidation_0-rmse:2.54967\tvalidation_1-rmse:2.04988\n",
      "[57]\tvalidation_0-rmse:2.54403\tvalidation_1-rmse:2.04539\n",
      "[58]\tvalidation_0-rmse:2.54123\tvalidation_1-rmse:2.04655\n",
      "[59]\tvalidation_0-rmse:2.53903\tvalidation_1-rmse:2.04545\n",
      "[60]\tvalidation_0-rmse:2.53487\tvalidation_1-rmse:2.04324\n",
      "[61]\tvalidation_0-rmse:2.53129\tvalidation_1-rmse:2.04453\n",
      "[62]\tvalidation_0-rmse:2.52981\tvalidation_1-rmse:2.04579\n",
      "[63]\tvalidation_0-rmse:2.52773\tvalidation_1-rmse:2.04468\n",
      "[64]\tvalidation_0-rmse:2.52559\tvalidation_1-rmse:2.04541\n",
      "[65]\tvalidation_0-rmse:2.52259\tvalidation_1-rmse:2.0432\n",
      "[66]\tvalidation_0-rmse:2.52063\tvalidation_1-rmse:2.04226\n",
      "[67]\tvalidation_0-rmse:2.51895\tvalidation_1-rmse:2.04076\n",
      "[68]\tvalidation_0-rmse:2.51375\tvalidation_1-rmse:2.04039\n",
      "[69]\tvalidation_0-rmse:2.51147\tvalidation_1-rmse:2.0416\n",
      "[70]\tvalidation_0-rmse:2.50817\tvalidation_1-rmse:2.04235\n",
      "[71]\tvalidation_0-rmse:2.50382\tvalidation_1-rmse:2.04526\n",
      "[72]\tvalidation_0-rmse:2.50048\tvalidation_1-rmse:2.04101\n",
      "[73]\tvalidation_0-rmse:2.49871\tvalidation_1-rmse:2.04121\n",
      "[74]\tvalidation_0-rmse:2.49425\tvalidation_1-rmse:2.04716\n",
      "[75]\tvalidation_0-rmse:2.4927\tvalidation_1-rmse:2.05601\n",
      "[76]\tvalidation_0-rmse:2.49115\tvalidation_1-rmse:2.05465\n",
      "[77]\tvalidation_0-rmse:2.488\tvalidation_1-rmse:2.05312\n",
      "[78]\tvalidation_0-rmse:2.48519\tvalidation_1-rmse:2.05165\n",
      "Stopping. Best iteration:\n",
      "[68]\tvalidation_0-rmse:2.51375\tvalidation_1-rmse:2.04039\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.8, eta=0.3, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=15, min_child_weight=300, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=None,\n",
       "       subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor(\n",
    "    max_depth=15,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42)\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
